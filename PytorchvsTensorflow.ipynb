{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f6af5b9-5601-42b4-aa77-8e1da750e822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8395960b-7b11-4890-9734-3365c4d8fdf5",
   "metadata": {},
   "source": [
    "### which one is better? Pytorch or Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90674575-f675-491f-9a06-009d3ed1252f",
   "metadata": {},
   "source": [
    "# PyTorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b0934a-606e-4ecf-bbce-a8a6b7cdde53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "942f8573-dd6e-40bd-af12-120c1d1375e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x282867ad050>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddaff70d-d940-496c-9631-86f0f77348ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "245e7278-4a92-4248-984e-2915cf5d45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "validation_split = 0.1\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b72779ab-51ba-4d7a-bf95-bc038e84ac45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e11bbe13932498d8ed1de6ef62a0966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\cifar-10-python.tar.gz to data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "training_set = datasets.CIFAR10(root='data', train=True, download=True, transform=ToTensor())\n",
    "test_set = datasets.CIFAR10(root='data', train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1f5b0a-0898-4e9d-be43-1982d6e6b672",
   "metadata": {},
   "source": [
    "## Note that the ToTensor() transformation from PIL images to tensors automatically turns the pixels’ value range from[0 255] to [0 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5836ae88-9e41-455b-bf4e-7df22b191534",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = int((1 - validation_split) * len(training_set))\n",
    "validation_size = int(validation_split * len(training_set))\n",
    "training_set, validation_set = random_split(training_set, [training_size, validation_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bdcf62-d8cd-4b76-9a2d-9073c3a7a9ed",
   "metadata": {},
   "source": [
    "### We define our data loaders for the training, validation and test sets. A DataLoader is an iterable over a data set that takes care of splitting it into mini-batches and reshuffling it at every epoch of the training to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6907e9ef-7663-4106-bc09-282878053765",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa19a2-3e0c-494a-9fc1-24f5f55e0c3d",
   "metadata": {},
   "source": [
    "### Now we build our neural network model. In this experiment, I’m going to define a CNN with two convolutional layers. The first layer will have 32 filters of size 3 × 3, and the second one will have 64 filters of size 3 × 3. After each convolution layer, we will add a max pooling layer and a dropout layer with a dropout rate of 25%. After the two convolutional layers we have two fully-connected layers, one with 512 neurons and the final output layer with 10 neurons (corresponding to the 10 CIFAR-10 classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85751de4-f159-4b10-b7e9-cb05d65ebea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(   \n",
    "    # A convolution layer with 32 filters of size 3x3\n",
    "    nn.Conv2d(3, 32, 3),             \n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),                 \n",
    "    nn.Dropout(0.25),\n",
    "\n",
    "    # A convolutional layer with 64 filters of size 3x3\n",
    "    nn.Conv2d(32, 64, 3),            \n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),                 \n",
    "    nn.Dropout(0.25),\n",
    "\n",
    "    # A fully-connected layer with 512 neurons\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64 * 6 * 6, 512),      \n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "\n",
    "    # The final output layer with 10 neurons\n",
    "    nn.Linear(512, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b614fb7-2fee-41ae-a7ff-500e97cd9daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Dropout(p=0.25, inplace=False)\n",
       "  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (5): ReLU()\n",
       "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (7): Dropout(p=0.25, inplace=False)\n",
       "  (8): Flatten(start_dim=1, end_dim=-1)\n",
       "  (9): Linear(in_features=2304, out_features=512, bias=True)\n",
       "  (10): ReLU()\n",
       "  (11): Dropout(p=0.5, inplace=False)\n",
       "  (12): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device) # We also need to place the model on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6858c45-3da9-4cfb-b950-911a5ff91948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, data_loader, loss_fn, optimizer):  \n",
    "    size = len(data_loader.dataset)  \n",
    "\n",
    "    for batch, (X, y) in enumerate(data_loader):  \n",
    "        # Place the data on the GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        \n",
    "        # Print the loss every 100 mini-batches\n",
    "        if (batch + 1) % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f2c9973-a260-4391-8584-4c62b0c756e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    size = len(data_loader.dataset)\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:            \n",
    "            X, y = X.to(device), y.to(device)\n",
    "            output = model(X)\n",
    "            y_pred = output.argmax(1)  \n",
    "            correct += (y_pred == y).sum().item()\n",
    "    return 100 * correct / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03d8fef7-3271-4b62-9fec-b0b9b4bdf970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loss_fn, optimizer):\n",
    "    train_start_time = time.time()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f'Epoch {epoch + 1}\\n-------------------------------')\n",
    "        \n",
    "        epoch_start_time = time.time()\n",
    "        model.train() # Ensure the dropout layers are in training mode\n",
    "        train_loop(model, train_loader, loss_fn, optimizer)        \n",
    "        model.eval() # Set dropout layers to evaluation mode\n",
    "        val_accuracy = evaluate_model(model, validation_loader)\n",
    "        epoch_elapsed_time = time.time() - epoch_start_time      \n",
    "        \n",
    "        print(f'Epoch {epoch + 1} completed in {epoch_elapsed_time:.3f}s, ' \n",
    "              f'val_accuracy: {val_accuracy:.3f}%\\n')\n",
    "    \n",
    "    train_elapsed_time = time.time() - train_start_time\n",
    "    print(f'Training completed in {train_elapsed_time:.3f}s')\n",
    "\n",
    "    model.eval()\n",
    "    train_accuracy = evaluate_model(model, train_loader)\n",
    "    print(f'Accuracy on training set: {train_accuracy:.3f}%')\n",
    "    test_accuracy = evaluate_model(model, test_loader)\n",
    "    print(f'Accuracy on test set: {test_accuracy:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6338857-6b25-4bcf-a3cc-32a37361a673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.970100  [ 3200/45000]\n",
      "loss: 1.650105  [ 6400/45000]\n",
      "loss: 1.930462  [ 9600/45000]\n",
      "loss: 1.731111  [12800/45000]\n",
      "loss: 1.554985  [16000/45000]\n",
      "loss: 1.849732  [19200/45000]\n",
      "loss: 1.569666  [22400/45000]\n",
      "loss: 1.886702  [25600/45000]\n",
      "loss: 1.291531  [28800/45000]\n",
      "loss: 1.833465  [32000/45000]\n",
      "loss: 1.564703  [35200/45000]\n",
      "loss: 1.482798  [38400/45000]\n",
      "loss: 1.628996  [41600/45000]\n",
      "loss: 1.355355  [44800/45000]\n",
      "Epoch 1 completed in 14.163s, val_accuracy: 52.880%\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.384692  [ 3200/45000]\n",
      "loss: 1.235805  [ 6400/45000]\n",
      "loss: 1.273409  [ 9600/45000]\n",
      "loss: 1.245774  [12800/45000]\n",
      "loss: 1.297815  [16000/45000]\n",
      "loss: 1.287188  [19200/45000]\n",
      "loss: 1.724888  [22400/45000]\n",
      "loss: 1.475049  [25600/45000]\n",
      "loss: 1.221546  [28800/45000]\n",
      "loss: 1.244520  [32000/45000]\n",
      "loss: 1.501837  [35200/45000]\n",
      "loss: 1.464387  [38400/45000]\n",
      "loss: 1.288455  [41600/45000]\n",
      "loss: 1.869904  [44800/45000]\n",
      "Epoch 2 completed in 8.152s, val_accuracy: 57.920%\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.270174  [ 3200/45000]\n",
      "loss: 1.177385  [ 6400/45000]\n",
      "loss: 0.977215  [ 9600/45000]\n",
      "loss: 1.105393  [12800/45000]\n",
      "loss: 1.515870  [16000/45000]\n",
      "loss: 1.251422  [19200/45000]\n",
      "loss: 1.354259  [22400/45000]\n",
      "loss: 1.284109  [25600/45000]\n",
      "loss: 1.187007  [28800/45000]\n",
      "loss: 0.828390  [32000/45000]\n",
      "loss: 1.029973  [35200/45000]\n",
      "loss: 1.324820  [38400/45000]\n",
      "loss: 1.243478  [41600/45000]\n",
      "loss: 1.233578  [44800/45000]\n",
      "Epoch 3 completed in 8.223s, val_accuracy: 63.880%\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.157735  [ 3200/45000]\n",
      "loss: 0.929710  [ 6400/45000]\n",
      "loss: 1.132156  [ 9600/45000]\n",
      "loss: 1.009161  [12800/45000]\n",
      "loss: 1.070249  [16000/45000]\n",
      "loss: 0.959082  [19200/45000]\n",
      "loss: 1.031202  [22400/45000]\n",
      "loss: 0.959872  [25600/45000]\n",
      "loss: 0.782621  [28800/45000]\n",
      "loss: 1.056327  [32000/45000]\n",
      "loss: 1.241949  [35200/45000]\n",
      "loss: 0.953849  [38400/45000]\n",
      "loss: 1.097302  [41600/45000]\n",
      "loss: 1.233288  [44800/45000]\n",
      "Epoch 4 completed in 8.132s, val_accuracy: 64.380%\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.836325  [ 3200/45000]\n",
      "loss: 0.911904  [ 6400/45000]\n",
      "loss: 0.787084  [ 9600/45000]\n",
      "loss: 1.504829  [12800/45000]\n",
      "loss: 1.139446  [16000/45000]\n",
      "loss: 1.197364  [19200/45000]\n",
      "loss: 1.614630  [22400/45000]\n",
      "loss: 0.642815  [25600/45000]\n",
      "loss: 1.059167  [28800/45000]\n",
      "loss: 1.245268  [32000/45000]\n",
      "loss: 1.088674  [35200/45000]\n",
      "loss: 1.166288  [38400/45000]\n",
      "loss: 0.818923  [41600/45000]\n",
      "loss: 0.970425  [44800/45000]\n",
      "Epoch 5 completed in 8.127s, val_accuracy: 64.280%\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.905995  [ 3200/45000]\n",
      "loss: 1.025505  [ 6400/45000]\n",
      "loss: 1.123516  [ 9600/45000]\n",
      "loss: 0.779096  [12800/45000]\n",
      "loss: 0.893096  [16000/45000]\n",
      "loss: 1.174932  [19200/45000]\n",
      "loss: 0.891346  [22400/45000]\n",
      "loss: 0.674139  [25600/45000]\n",
      "loss: 1.198956  [28800/45000]\n",
      "loss: 1.075941  [32000/45000]\n",
      "loss: 1.243301  [35200/45000]\n",
      "loss: 1.096797  [38400/45000]\n",
      "loss: 1.060789  [41600/45000]\n",
      "loss: 0.922026  [44800/45000]\n",
      "Epoch 6 completed in 8.181s, val_accuracy: 67.460%\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.793224  [ 3200/45000]\n",
      "loss: 0.886252  [ 6400/45000]\n",
      "loss: 0.881828  [ 9600/45000]\n",
      "loss: 0.941921  [12800/45000]\n",
      "loss: 1.121756  [16000/45000]\n",
      "loss: 0.838496  [19200/45000]\n",
      "loss: 1.198058  [22400/45000]\n",
      "loss: 0.880452  [25600/45000]\n",
      "loss: 1.169449  [28800/45000]\n",
      "loss: 0.909094  [32000/45000]\n",
      "loss: 1.028337  [35200/45000]\n",
      "loss: 0.931601  [38400/45000]\n",
      "loss: 0.752308  [41600/45000]\n",
      "loss: 0.999846  [44800/45000]\n",
      "Epoch 7 completed in 8.143s, val_accuracy: 67.900%\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.948353  [ 3200/45000]\n",
      "loss: 0.908432  [ 6400/45000]\n",
      "loss: 0.842299  [ 9600/45000]\n",
      "loss: 0.974070  [12800/45000]\n",
      "loss: 1.013001  [16000/45000]\n",
      "loss: 0.825682  [19200/45000]\n",
      "loss: 0.759031  [22400/45000]\n",
      "loss: 0.660206  [25600/45000]\n",
      "loss: 0.778476  [28800/45000]\n",
      "loss: 0.921950  [32000/45000]\n",
      "loss: 1.198907  [35200/45000]\n",
      "loss: 1.438347  [38400/45000]\n",
      "loss: 1.005038  [41600/45000]\n",
      "loss: 0.807048  [44800/45000]\n",
      "Epoch 8 completed in 8.169s, val_accuracy: 69.100%\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.712417  [ 3200/45000]\n",
      "loss: 0.942725  [ 6400/45000]\n",
      "loss: 0.749721  [ 9600/45000]\n",
      "loss: 1.079358  [12800/45000]\n",
      "loss: 0.819718  [16000/45000]\n",
      "loss: 0.919142  [19200/45000]\n",
      "loss: 0.973989  [22400/45000]\n",
      "loss: 1.130324  [25600/45000]\n",
      "loss: 0.954920  [28800/45000]\n",
      "loss: 0.787234  [32000/45000]\n",
      "loss: 1.032353  [35200/45000]\n",
      "loss: 1.069302  [38400/45000]\n",
      "loss: 1.307850  [41600/45000]\n",
      "loss: 0.954887  [44800/45000]\n",
      "Epoch 9 completed in 8.145s, val_accuracy: 69.980%\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.664192  [ 3200/45000]\n",
      "loss: 0.981403  [ 6400/45000]\n",
      "loss: 0.668025  [ 9600/45000]\n",
      "loss: 1.099784  [12800/45000]\n",
      "loss: 0.874597  [16000/45000]\n",
      "loss: 0.792923  [19200/45000]\n",
      "loss: 1.080429  [22400/45000]\n",
      "loss: 1.206839  [25600/45000]\n",
      "loss: 0.736240  [28800/45000]\n",
      "loss: 1.208416  [32000/45000]\n",
      "loss: 1.266329  [35200/45000]\n",
      "loss: 0.769178  [38400/45000]\n",
      "loss: 0.893236  [41600/45000]\n",
      "loss: 1.305289  [44800/45000]\n",
      "Epoch 10 completed in 8.192s, val_accuracy: 69.580%\n",
      "\n",
      "Training completed in 87.630s\n",
      "Accuracy on training set: 78.173%\n",
      "Accuracy on test set: 70.180%\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5066af9-0f46-4e8d-adb4-76baeeb9c8b6",
   "metadata": {},
   "source": [
    "## TensorFlow Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6579c6c4-842d-4a67-ac7d-ada19319fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f2b4cc6-38a8-4a39-9f14-fbd69d214f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0) # fix the random seed for consistency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27934cc1-6d22-410b-9ffb-f8972cbac6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "validation_split = 0.1\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2eef7a2-d179-4800-98fd-8ea92cdb6760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 48s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f4e345-d458-4e6d-95e3-e2fe67b2bcb3",
   "metadata": {},
   "source": [
    "## We scale the data to be in the range [0, 1] instead of [0, 255] (In PyTorch this was already taken care for us by the ToTensor() transformer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f14bb148-b421-49de-bf72-a2b950a18e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87a777e3-c89f-400b-b497-dbde0ba8b79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([  \n",
    "    layers.Conv2D(32, 3, input_shape=[32, 32, 3], activation='relu', kernel_initializer='he_uniform'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(64, 3, activation='relu', kernel_initializer='he_uniform'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu', kernel_initializer='he_uniform'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax', kernel_initializer='he_uniform')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b81a7ad-1cd9-4a07-9e45-784ab5369ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1180160   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,204,682\n",
      "Trainable params: 1,204,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0955014-d194-4a3e-aa20-f86d333d863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8339a84b-b5f2-4552-843f-61aee4cdf769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 7s 4ms/step - loss: 1.6024 - accuracy: 0.4185 - val_loss: 1.2555 - val_accuracy: 0.5556\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.2495 - accuracy: 0.5560 - val_loss: 1.0542 - val_accuracy: 0.6296\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1097 - accuracy: 0.6062 - val_loss: 0.9580 - val_accuracy: 0.6850\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 1.0181 - accuracy: 0.6437 - val_loss: 0.9041 - val_accuracy: 0.6904\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.9598 - accuracy: 0.6646 - val_loss: 0.8475 - val_accuracy: 0.7050\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.9022 - accuracy: 0.6820 - val_loss: 0.8363 - val_accuracy: 0.7172\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.8558 - accuracy: 0.6972 - val_loss: 0.8190 - val_accuracy: 0.7220\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.8196 - accuracy: 0.7126 - val_loss: 0.7880 - val_accuracy: 0.7304\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.7908 - accuracy: 0.7236 - val_loss: 0.7847 - val_accuracy: 0.7330\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.7588 - accuracy: 0.7328 - val_loss: 0.7998 - val_accuracy: 0.7338\n",
      "Training completed in 63.456s\n"
     ]
    }
   ],
   "source": [
    "train_start_time = time.time()\n",
    "model.fit(X_train, y_train, batch_size=batch_size, \n",
    "          epochs=n_epochs, validation_split=validation_split)\n",
    "train_elapsed_time = time.time() - train_start_time\n",
    "print(f'Training completed in {train_elapsed_time:.3f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e9a7a75-9c69-49f8-a60d-bfec77f59d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 83.494%\n",
      "Accuracy on test set: 71.840%\n"
     ]
    }
   ],
   "source": [
    "train_results = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(f'Accuracy on training set: {train_results[1] * 100:.3f}%')\n",
    "\n",
    "test_results = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Accuracy on test set: {test_results[1] * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b17e215-dbb8-48a2-8e69-8bfe5c3dc4d5",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "From this little experiment we can conclude that:\n",
    "\n",
    "Training the model using TensorFlow is much faster and also accuracy is higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9497e-c121-4298-865d-3897be7312bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
